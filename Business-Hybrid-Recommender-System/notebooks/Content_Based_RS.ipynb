{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e058c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import spatial\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35655750",
   "metadata": {},
   "source": [
    "## Importación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d0af499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \n",
    "    dataset_path = 'dataset/'\n",
    "    df_business = pd.read_json(dataset_path + 'business.json', lines=True)\n",
    "    \n",
    "    size = 1000000\n",
    "    df_reviews = pd.read_json(dataset_path + 'review.json', lines=True, \n",
    "                          dtype={'review_id':str,'user_id':str,\n",
    "                                 'business_id':str,'stars':int,\n",
    "                                 'date':str,'text':str,'useful':int,\n",
    "                                 'funny':int,'cool':int},\n",
    "                          chunksize=size)\n",
    "    reviews_list = []\n",
    "    for df_review in tqdm(df_reviews):\n",
    "        df_review = df_review.drop(['review_id','useful','funny','cool'], axis=1)\n",
    "        df_review = df_review.rename(columns={'stars': 'review_stars'})\n",
    "        df_review_m = pd.merge(df_business, df_review, on='business_id', how='inner')\n",
    "        reviews_list.append(df_review_m)\n",
    "\n",
    "    df_review = pd.concat(reviews_list, ignore_index=True, join='outer', axis=0)\n",
    "    return df_review, df_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1addbbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_user(df_review, user_ids, non_seen_items):\n",
    "    user_cities = list(df_review[df_review['user_id'].isin(user_ids)]['city'].values)\n",
    "    user_items = list(set(list(df_review[df_review['user_id'].isin(user_ids)]['business_id'])))\n",
    "    reviews_user = df_review[(df_review['city'].isin(user_cities)) & (df_review['business_id'].isin(user_items))]\n",
    "    if non_seen_items:\n",
    "        user_cities = list(df_review[df_review['user_id'].isin([user_ids[0]])]['city'].values)\n",
    "        user_items = list(set(list(df_review[df_review['user_id'].isin([user_ids[0]])]['business_id'])))\n",
    "        non_seen_items = df_review[(df_review['city'].isin(user_cities)) & (df_review['business_id'].isin(user_items) == False)]\n",
    "        return reviews_user, non_seen_items[['business_id', 'user_id', 'review_stars']]\n",
    "    else:\n",
    "        return reviews_user, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd2d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(matrix):\n",
    "    return 1-pairwise_distances(matrix, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6be3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_users(df_reviews_user, user_id):\n",
    "    \n",
    "    reviews_user = df_reviews_user[['user_id', 'business_id', 'review_stars']].drop_duplicates()\n",
    "    review_user_matrix = reviews_user.pivot_table(values='review_stars', index='user_id', columns='business_id').fillna(0)\n",
    "    idx = list(review_user_matrix.index)\n",
    "    cosine_sim = cosine_similarity(review_user_matrix)\n",
    "    cosine_sim_matrix = pd.DataFrame(data = cosine_sim, index = idx, columns = idx)\n",
    "    user_sim = cosine_sim_matrix.filter(items=[user_id], axis=0)\n",
    "    most_sim_k_users = user_sim.max().rename_axis('user').reset_index().sort_values(by=0, ascending=False)\n",
    "    most_sim_k_users.columns = ['user_id', 'similarity']\n",
    "    \n",
    "    return most_sim_k_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9423526f",
   "metadata": {},
   "source": [
    "## Sistema de recomendación basado en Contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caee4741",
   "metadata": {},
   "source": [
    "## Preprocesmiento de las caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6cc432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_business_features(df_business, reprocess):\n",
    "    if reprocess:\n",
    "        df_business = pd.concat([df_business.drop(['attributes'], axis=1), df_business['attributes'].apply(pd.Series)], axis=1)\n",
    "        categories = [x.split(',') for x in list(df_business['categories']) if x != None]\n",
    "        categories = list(set([x.lstrip() for x in [item for sublist in categories for item in sublist]]))\n",
    "\n",
    "        for category in categories:\n",
    "            column_name = category.replace(' ', '_').replace('-','_').replace('/','_').lower()\n",
    "            df_business[category] = df_business['categories'].str.contains(category)\n",
    "\n",
    "        delete_cols = ['address', 'state', 'postal_code', 'latitude', 'longitude', 'categories', 'hours', 'review_count', \\\n",
    "                       'is_open', 'city', 'stars']\n",
    "        df_business = df_business.drop(columns = delete_cols)\n",
    "\n",
    "        dict_cols = ['BusinessParking','Ambience','GoodForMeal','Music', 'BestNights', 'HairSpecializesIn', \\\n",
    "                     'DietaryRestrictions']\n",
    "        new_cols = []\n",
    "        for dict_col in tqdm(dict_cols):\n",
    "            new_df = df_business[dict_col].apply(pd.Series)\n",
    "            new_cols.append(new_df.columns)\n",
    "            df_business = pd.concat([df_business.drop([dict_col], axis=1), new_df], axis=1)\n",
    "\n",
    "        unicode_cols = ['Alcohol', 'WiFi', 'RestaurantsAttire', 'NoiseLevel', 'Smoking', 'BYOBCorkage', 'AgesAllowed']\n",
    "        for unicode_col in tqdm(unicode_cols):\n",
    "            df_business[unicode_col] = df_business[unicode_col].str.replace('u', '')\n",
    "\n",
    "        df_business = df_business.replace('True', '1').replace('False', '0').fillna('0')\n",
    "        df_business = df_business.replace(True, '1').replace(False, '0').replace('None','0')\n",
    "        df_business = df_business.drop(0, axis=1)\n",
    "\n",
    "        avoid_cols = ['business_id', 'city'] + dict_cols + unicode_cols\n",
    "        transform_cols = [x for x in df_business.columns if x not in avoid_cols]\n",
    "        for col in tqdm(transform_cols):\n",
    "            df_business[col] = df_business[col].fillna(0)\n",
    "            df_business[col] = df_business[col].astype(int)\n",
    "\n",
    "        df_business['WiFi'] = df_business['WiFi'].replace('0', 'no specify')\n",
    "        df_business['Alcohol'] = df_business['Alcohol'].replace('0', 'no specify')\n",
    "        df_business['RestaurantsAttire'] = df_business['RestaurantsAttire'].replace(0, 'no specify')\n",
    "        df_business['NoiseLevel'] = df_business['NoiseLevel'].replace('0', 'no specify')\n",
    "        df_business['Smoking'] = df_business['Smoking'].replace('0', 'no specify')\n",
    "        df_business['BYOBCorkage'] = df_business['BYOBCorkage'].replace('0', 'no specify')\n",
    "        df_business['AgesAllowed'] = df_business['AgesAllowed'].replace('0', 'no specify')\n",
    "\n",
    "        cat_cols = ['WiFi', 'Alcohol', 'RestaurantsAttire', 'NoiseLevel', 'Smoking', 'BYOBCorkage', 'AgesAllowed']\n",
    "        df_business = pd.get_dummies(df_business, columns=cat_cols)\n",
    "    else:\n",
    "        df_business= pd.read_pickle('df_business_transformed.pkl')\n",
    "    \n",
    "    return df_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64aabbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_features(df_review, df_business, similarity_users, user_id, K_users):\n",
    "    \n",
    "    users_id = list(similarity_users.head(K_users+1)['user_id'])\n",
    "    df_reviews_user, df_non_seen_items = filter_by_user(df_review, users_id, True)\n",
    "    df_non_seen_items = df_non_seen_items[['business_id']].drop_duplicates()\n",
    "\n",
    "    df_business_features = transform_business_features(df_business, reprocess = False)\n",
    "    df_reviews_user = df_reviews_user[['business_id', 'review_stars']].merge(df_business_features, on='business_id', how='left')\n",
    "    \n",
    "    cols_X = [x for x in df_reviews_user.columns if x not in ['business_id', 'review_stars', 'city', 'stars']]\n",
    "    X, y = df_reviews_user[cols_X], df_reviews_user['review_stars']\n",
    "    \n",
    "    pesos_features, pval= chi2(X, y)\n",
    "    pesos_features = np.nan_to_num(pesos_features)\n",
    "    pesos_features_mask = pesos_features>0\n",
    "    X = X[X.columns[pesos_features_mask]]\n",
    "    \n",
    "    df_non_seen_items = df_non_seen_items.merge(df_business_features, on='business_id', how='left')\n",
    "    X_rec, y_rec = df_non_seen_items[X.columns], df_non_seen_items[['business_id']]\n",
    "    \n",
    "    return X, y, X_rec, y_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f62bac",
   "metadata": {},
   "source": [
    "### Extracción de caracteristicas mas importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2009b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(X, y, X_rec, y_rec, K_rec):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    model = KNeighborsClassifier(2)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    prec, recall, fscore, supp = precision_recall_fscore_support(y_test, y_pred)\n",
    "    message = \"\"\" Promedio de Precisión del modelo: {} \\n Promedio de Cobertura del modelo: {} \\n Promedio de Medida F del modelo: {}\"\"\"\n",
    "    print(message.format(np.mean(prec), np.mean(recall), np.mean(fscore)))\n",
    "    \n",
    "    predictions = model.predict(X_rec)\n",
    "    df_pred = pd.DataFrame(data = y_rec, columns=['business_id'])\n",
    "    df_pred.loc[:, ['review_stars_predicted']] = predictions\n",
    "    \n",
    "    df_pred = df_pred.sort_values(by='review_stars_predicted', ascending=False).head(K_rec)\n",
    "    df_pred = df_pred.merge(df_business, on='business_id', how='left')[['name', 'address', 'city', 'state', 'review_stars_predicted']]\n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b21846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [03:49, 32.74s/it]\n"
     ]
    }
   ],
   "source": [
    "user_id = 'MR_0VqlmaHRBskfq_u9UaA'\n",
    "K_sim_user = 10\n",
    "K_rec = 10\n",
    "\n",
    "df_review, df_business = load_dataset()\n",
    "df_reviews_user, df_non_seen_items = filter_by_user(df_review, [user_id], True)\n",
    "similarity_users = get_similarity_users(df_reviews_user, user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4d8c230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Promedio de Precisión del modelo: 0.24408017562438547\n",
      "    Promedio de Cobertura del modelo: 0.24876622800098577\n",
      "    Promedio de Medida F del modelo: 0.22868379989176826\n"
     ]
    }
   ],
   "source": [
    "X, y, X_rec, y_rec = extract_user_features(df_review, df_business, similarity_users, user_id, K_sim_user)\n",
    "\n",
    "predictions = generate_recommendations(X, y, X_rec, y_rec, K_rec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
